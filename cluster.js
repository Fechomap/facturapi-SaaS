// cluster.js - ConfiguraciÃ³n de clustering para escalabilidad masiva
import cluster from 'cluster';
import os from 'os';
import logger from './core/utils/logger.js';

const clusterLogger = logger.child({ module: 'cluster' });

// Determinar nÃºmero de workers segÃºn el entorno
const getWorkerCount = () => {
  const cpuCount = os.cpus().length;
  const isProduction = process.env.NODE_ENV === 'production';
  const isRailway = process.env.IS_RAILWAY === 'true' || Boolean(process.env.RAILWAY_ENVIRONMENT);

  // En Railway podemos usar mÃ¡s workers debido a su infraestructura
  if (isRailway && isProduction) {
    // Railway permite hasta 8 workers eficientemente
    return Math.min(cpuCount * 2, 8);
  } else if (isProduction) {
    // En producciÃ³n general, usar todos los CPUs disponibles
    return cpuCount;
  } else {
    // En desarrollo, solo 2 workers para no saturar
    return Math.min(cpuCount, 2);
  }
};

// ConfiguraciÃ³n del cluster
const workerCount = getWorkerCount();
const WORKER_RESTART_DELAY = 1000; // 1 segundo
const MAX_RESTARTS_PER_MINUTE = 5;

const restartCounts = new Map();

if (cluster.isPrimary) {
  clusterLogger.info(`ğŸš€ Iniciando cluster principal con ${workerCount} workers`);
  clusterLogger.info(`ğŸ’» CPUs detectados: ${os.cpus().length}`);
  clusterLogger.info(`ğŸ­ Entorno: ${process.env.NODE_ENV}`);
  clusterLogger.info(`ğŸš‚ Railway: ${process.env.IS_RAILWAY === 'true' ? 'SÃ­' : 'No'}`);

  // FunciÃ³n para limpiar contadores de restart cada minuto
  setInterval(() => {
    restartCounts.clear();
  }, 60000);

  // FunciÃ³n para crear un worker
  const createWorker = () => {
    const worker = cluster.fork();

    worker.on('online', () => {
      clusterLogger.info(`ğŸ‘· Worker ${worker.process.pid} iniciado correctamente`);
    });

    return worker;
  };

  // Crear workers iniciales
  for (let i = 0; i < workerCount; i++) {
    createWorker();
  }

  // Manejar workers que mueren
  cluster.on('exit', (worker, code, signal) => {
    const pid = worker.process.pid;

    if (signal) {
      clusterLogger.warn(`ğŸ’€ Worker ${pid} terminado por seÃ±al ${signal}`);
    } else if (code !== 0) {
      clusterLogger.error(`ğŸ’€ Worker ${pid} fallÃ³ con cÃ³digo ${code}`);
    } else {
      clusterLogger.info(`âœ… Worker ${pid} terminado correctamente`);
    }

    // Solo reiniciar automÃ¡ticamente si no fue una terminaciÃ³n intencional
    if (signal !== 'SIGTERM' && signal !== 'SIGINT') {
      const workerId = worker.id;
      const currentRestarts = restartCounts.get(workerId) || 0;

      if (currentRestarts < MAX_RESTARTS_PER_MINUTE) {
        clusterLogger.info(`ğŸ”„ Reiniciando worker ${workerId} en ${WORKER_RESTART_DELAY}ms`);

        setTimeout(() => {
          createWorker();
          restartCounts.set(workerId, currentRestarts + 1);
        }, WORKER_RESTART_DELAY);
      } else {
        clusterLogger.error(
          `âš ï¸ Worker ${workerId} ha fallado demasiadas veces, no se reiniciarÃ¡ automÃ¡ticamente`
        );
      }
    }
  });

  // Manejar seÃ±ales del sistema para cierre limpio
  const shutdown = (signal) => {
    clusterLogger.info(`ğŸ“´ Recibida seÃ±al ${signal}, cerrando cluster...`);

    for (const id in cluster.workers) {
      cluster.workers[id].kill('SIGTERM');
    }

    // Forzar cierre despuÃ©s de 10 segundos
    setTimeout(() => {
      clusterLogger.warn('â° Forzando cierre del cluster');
      process.exit(0);
    }, 10000);
  };

  process.on('SIGTERM', () => shutdown('SIGTERM'));
  process.on('SIGINT', () => shutdown('SIGINT'));

  // EstadÃ­sticas del cluster cada 5 minutos
  setInterval(
    () => {
      const workerIds = Object.keys(cluster.workers);
      clusterLogger.info(`ğŸ“Š Cluster activo: ${workerIds.length}/${workerCount} workers`);

      // InformaciÃ³n de memoria y CPU
      const memUsage = process.memoryUsage();
      clusterLogger.info(`ğŸ’¾ Memoria principal: ${Math.round(memUsage.rss / 1024 / 1024)}MB`);
    },
    5 * 60 * 1000
  );
} else {
  // CÃ³digo del worker - importar y ejecutar el servidor
  clusterLogger.info(`ğŸ‘· Worker ${process.pid} iniciando...`);

  // Importar dinÃ¡micamente el servidor para evitar problemas de clustering
  import('./server.js').catch((error) => {
    clusterLogger.error(`âŒ Error al iniciar worker ${process.pid}:`, error);
    process.exit(1);
  });

  // Manejar errores no capturados en workers - GRACEFUL HANDLING
  process.on('uncaughtException', (error) => {
    clusterLogger.error(`ğŸ’¥ Error no capturado en worker ${process.pid}:`, {
      message: error.message,
      stack: error.stack,
      timestamp: new Date().toISOString(),
    });

    // Solo salir si es un error crÃ­tico del sistema
    if (error.code === 'EADDRINUSE' || error.code === 'EACCES' || !error.recoverable) {
      clusterLogger.fatal('Error crÃ­tico del sistema, terminando worker');
      process.exit(1);
    } else {
      clusterLogger.warn('Error recuperable, continuando operaciÃ³n');
    }
  });

  process.on('unhandledRejection', (reason, promise) => {
    clusterLogger.error(`ğŸš« Promesa rechazada no manejada en worker ${process.pid}:`, {
      reason: reason?.message || reason,
      stack: reason?.stack,
      promise: promise?.toString?.() || 'Promise sin informaciÃ³n',
      timestamp: new Date().toISOString(),
    });

    // No terminar el proceso por promesas rechazadas - solo logear
    clusterLogger.warn('Continuando operaciÃ³n despuÃ©s de promesa rechazada');
  });
}

export default cluster;
